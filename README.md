# SoundSenseHelmet ğŸ›¡ï¸ğŸ§  
**AI-Powered Safety Helmet for the Deaf Community**  

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)  
[![Python 3.9+](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/)  
[![TensorFlow Lite](https://img.shields.io/badge/TensorFlow_Lite-2.10+-orange.svg)](https://www.tensorflow.org/lite)  

<div align="center">
  <img src="docs/helmet_demo.gif" width="400" alt="Demo">
</div>

## ğŸ—ï¸ Project Structure

```markdown
smart_helmet/ â”œâ”€â”€ client/ # Laptop audio streaming client â”‚ â””â”€â”€ audio_client.py â”œâ”€â”€ raspberry_pi/ # Core helmet system â”‚ â”œâ”€â”€ audio/ # Audio processing â”‚ â”‚ â”œâ”€â”€ audio_server.py # UDP server â”‚ â”‚ â”œâ”€â”€ audio_processor.py # Chunk handling â”‚ â”‚ â””â”€â”€ features.py # Spectrogram conversion â”‚ â”œâ”€â”€ ml/ # Machine learning â”‚ â”‚ â”œâ”€â”€ inference.py # Real-time prediction â”‚ â”‚ â”œâ”€â”€ model_loader.py # TFLite integration â”‚ â”‚ â””â”€â”€ models/ # Pretrained models â”‚ â”œâ”€â”€ sensors/ # Sensor interfaces â”‚ â”‚ â”œâ”€â”€ force_sensor.py # Impact detection â”‚ â”‚ â”œâ”€â”€ gps.py # Location tracking â”‚ â”‚ â””â”€â”€ mpu6050.py # Head tracking â”‚ â”œâ”€â”€ output/ # User feedback â”‚ â”‚ â”œâ”€â”€ haptic.py # Vibration control â”‚ â”‚ â””â”€â”€ visual.py # LED patterns â”‚ â”œâ”€â”€ utils/ # Utilities â”‚ â”‚ â”œâ”€â”€ alerts.py # Notification system â”‚ â”‚ â”œâ”€â”€ logger.py # Logging config â”‚ â”‚ â””â”€â”€ config.py # Hardware pin config â”œâ”€â”€ model_training/ # ML model development â”œâ”€â”€ tests/ # Unit tests â”‚ â”œâ”€â”€ test_audio_streaming.py â”‚ â”œâ”€â”€ test_ml_inference.py â”‚ â””â”€â”€ test_sensors.py â”œâ”€â”€ requirements.txt # Python dependencies â””â”€â”€ README.md
```

## ğŸš€ Key Features
- **Real-Time Audio Classification**  
  - Processes microphone input at 22.05kHz (50ms chunks)
  - Identifies sirens, horns, and emergency sounds
- **Multi-Sensor Integration**  
  - MPU6050 for head orientation tracking  
  - Force sensor for crash detection
  - GPS for emergency location logging
- **Tactile Feedback System**  
  - Configurable vibration patterns for different alerts
  - LED visual indicators

## ğŸ“¦ Hardware  
- Raspberry Pi 4  
- MEMS Microphone  
- MPU6050 (Head tracking)  
- GPS Module (NEO-6M)  
- Vibration Motors  

## ğŸ› ï¸ Setup
```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. Configure hardware pins
nano raspberry_pi/config.py

# 3. Start the system
# On Pi:
python raspberry_pi/main.py

# On laptop:
python client/audio_client.py --pi-ip 192.168.x.x
```
## ğŸ§ª Testing
```bash
# Run all tests
python -m pytest tests/

# Individual test modules
pytest tests/test_sensors.py
pytest tests/test_ml_inference.py -v
```

---

### **Recommended Tags**  
```markdown
Topics:  
assistive-technology, deaf-community, real-time-audio, raspberry-pi, tensorflow-lite, haptic-feedback, smart-helmet, accessibility
```
